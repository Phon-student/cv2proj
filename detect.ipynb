{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC pills box detection \n",
    "\n",
    "    This notebook is a work for pill box dent detection using edge detection and hough transform. Combinded with finding curves on the edges lines in picture to check if the box is in good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images in the first test set\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    path = Path(directory)\n",
    "    path = path.glob(\"*.png\")\n",
    "\n",
    "    images = []\n",
    "    # Iterate over all files with .png extension in the directory\n",
    "    for imagepath in path:\n",
    "        img = cv2.imread(str(imagepath))  # Read image from file\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert image to grayscale\n",
    "        images.append(img)\n",
    "\n",
    "\n",
    "    return images\n",
    "\n",
    "directory1 = \".dataset/damaged/side\" # Path to the directory containing the images\n",
    "\n",
    "\n",
    "images1 = load_images_from_directory(directory1)\n",
    "print(len(images1), \"images in the first test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(image, sigma=0.33):\n",
    "    # Convert the image to grayscale\n",
    "    v = np.median(image)\n",
    "    lower = int(max(100, (1.0 - sigma) * v))\n",
    "    upper = int(min(130, (1.0 + sigma) * v))\n",
    "\n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(image, lower, upper)\n",
    "    return edges\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find if there is a curve edges on the image\n",
    "def find_curved_edges(edges, min_angle=55, max_angle=160):\n",
    "    # Define the Hough transform parameters\n",
    "    rho = 0.77 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 70 # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 70 # minimum number of pixels making up a line\n",
    "    max_line_gap = 5 # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    # Run Hough on the edge-detected image\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "    # Iterate over the output \"lines\" and draw them on the image\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "            if min_angle <= abs(angle) <= max_angle:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_damage(images):\n",
    "    damage = 0\n",
    "    for image in images:\n",
    "        edges = edge_detection(image)\n",
    "        if find_curved_edges(edges):\n",
    "            damage += 1\n",
    "    return damage / len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate in finding damage 0.73\n"
     ]
    }
   ],
   "source": [
    "damage1 = predict_damage(images1)\n",
    "print(\"Success rate in finding damage\", damage1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR with easyocr\n",
    "\n",
    "    The OCR is done using easyocr to read the text on the pills box. The text is then used to check if the box is in true lable according to file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete100 images in the second test set\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "# Create an OCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "\n",
    "# Get a set of three from directory and feed them to the OCR model\n",
    "directory2 = \".dataset/damaged/side\" # Path to the directory containing the images\n",
    "images2 = load_images_from_directory(directory2)\n",
    "print(len(images2), \"images in the second test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path_number(directory):\n",
    "    path = Path(directory)\n",
    "    path = path.glob(\"*.png\")\n",
    "\n",
    "    path_no_suffix = []\n",
    "    # Iterate over all files with .png extension in the directory\n",
    "    for imagepath in path:\n",
    "        filename = Path(imagepath).stem\n",
    "        number = filename.split(\"_side\")[0].split(\"\\\\\")[-1]# Extract the number\n",
    "        path_no_suffix.append(number)\n",
    "    return path_no_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images_number = get_image_path_number(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_ocr(images):\n",
    "    num_results = []\n",
    "    for image in images:\n",
    "        result = reader.readtext(image)\n",
    "        num_results.extend([detection[1] for detection in result if detection[1].isdigit() and len(detection[1]) == 13])\n",
    "    return num_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_filename_with_ocr(images, ocr_result):\n",
    "    # both images and ocr_result to sets for faster membership testing\n",
    "    ocr_result_set = set(ocr_result)\n",
    "    \n",
    "    filenames = set(images)\n",
    "    # Find the common elements between the two sets\n",
    "    common_elements = ocr_result_set.intersection(filenames)\n",
    "    return len(common_elements) / len(ocr_result_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_SN(ocr_result):\n",
    "    return compare_filename_with_ocr(list_of_images_number, ocr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_SN() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess rate in finding serial numbers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpredict_SN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_text_from_ocr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: predict_SN() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "print(\"Success rate in finding serial numbers\", predict_SN(get_text_from_ocr(images2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "    - On the first part of the notebook we have a good detection of the damaged box .\n",
    "    - On the second part we have a good OCR detection of the text on the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
